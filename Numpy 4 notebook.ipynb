{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c6203f9",
   "metadata": {},
   "source": [
    "# <code style=\"background:yellow;color:black\">Summary:</code>\n",
    "\n",
    "1. Copies of data\n",
    "2. Shallow and how to create it using view() function\n",
    "3. Deep copy and how to create it using copy() function\n",
    "4. When numpy creates which copy and overview of memory management of numpy\n",
    "5. shares_memory() function to identify whether it is deep or shallow copy\n",
    "6. Splitting data\n",
    "7. Stacking data\n",
    "8. Concatenate data\n",
    "9. flatten() method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ccb080",
   "metadata": {},
   "source": [
    "<hr style=\"border: 1px solid gray;\">\n",
    "\n",
    "# <code style=\"background:yellow;color:black\">Copies of Data:</code>\n",
    "\n",
    "* **As a data scientist, we will be working with millions of rows of data. So, numpy on top of being very fast, also has to be memory efficient, because if its not memory efficient our computer or system might run out of memory, and we wont be able to work with that dataset.**\n",
    "\n",
    "* So ultimately, storage space is a baseline requirement for numpy to be able to work with data because memory is continuosly either occupied or freed with each line of the program or with execution every of task. **<code style=\"background:yellow;color:black\">Therefore, numpy internally has done a lot of optimizations so that it can optimize on storage / memory space.</code>**<br><br>\n",
    "\n",
    "* Lets suppose there is a bunch of data in excel. This data is for multiple cars. The cars data has 3 columns called Car model, Manufacturer and Date of launch. There are some entries i.e. rows in the data. **REFER NOTES TO SEE DATA.**\n",
    "\n",
    "* Lets suppose we only have to show data for tata, what would we do? Will we copy all the tata entries to another excel sheet or simply apply a filter to filter out tata entries? Obviously we will apply a filter on the manufacturer, which means that filter will show you us tata data only, but the rest of the data will still be there. \n",
    "\n",
    "* **It means internally all the data is present but only filtered data is visible to us as a user. OR WE CAN ALSO SAY THAT BOTH THE DATAFRAMES OR BOTH THESE SOURCES OF DATA IS THE SAME, WE ARE JUST LOOKING AT DIFFERENT VIEWS OF THE DATA.**\n",
    "\n",
    "* Internally there is one single dataset, but we are just looking at different views of that same data. In one view, we are looking at all the manufacturers and in another view we are only looking at tata data.<br><br>\n",
    "\n",
    "* **Now, when it comes to numpy, we are doing as lot of operations on data. Some of those operations are permananet and some of those opearations are operations which can be either reversible or changed or are only done to present the data in a different format. These operations do not change the structure or the value of the data but they just present the data differently.** \n",
    "\n",
    "* **So NUMPY AUTOMATICALLY HAS DIVIDED ALL ITS OPERATIONS INTO THESE TWO CATEGORIES.**\n",
    "\n",
    "    * **<code style=\"background:yellow;color:black\">Category 1</code>** are those opeartions which are permanent or important operations on data. \n",
    "\n",
    "    * **<code style=\"background:yellow;color:black\">Category 2</code>** are operations which are just on the look of data or view of the data. \n",
    "\n",
    "**AND IN BOTH THESE CASES NUMPY HANDLES MEMORY DIFFERENTLY. We will see this in action.** \n",
    "\n",
    "**In NumPy (and in Python in general), <code style=\"background:yellow;color:black\">the concepts of shallow copy and deep copy</code> refer to how the copying of objects is handled, especially when dealing with nested or compound objects like arrays or lists.**\n",
    "\n",
    "### <code style=\"background:yellow;color:black\">Shallow Copy of Data:</code> \n",
    "\n",
    "* **<code style=\"background:yellow;color:black\">A shallow copy</code> creates a new object, but does not create copies of the nested objects within the original object. Instead, it copies references to the nested objects. As a result, changes made to the nested objects within the copied object will be reflected in the original object, and vice versa.**\n",
    "\n",
    "* **<code style=\"background:yellow;color:black\">A shallow copy</code> of an array means a new array that is a copy of the original array's data and shape but shares the same memory addresses as the original array. In other words, both of these arrays are sharing the same memory addresses. Changes made to the data within a shallow copy will also affect the original array, and vice versa.**\n",
    "\n",
    "* If we look at a and b in the example code cell below, both a and b are similar in data but different in the view of that data, which means they look and feel different and are presented differently but the data within them is the same. **So in such cases, what numpy does is it creates a <code style=\"background:yellow;color:black\">SHALLOW COPY of data</code>.** \n",
    "\n",
    "* To prove it, below we are changing a[0] to 100, obviously \"a\" gets modified and now has 100 as its 1st element, **BUT B ALSO HAS THE SAME 100. IT ALSO CHANGED ITS 1ST ELEMENT.**  \n",
    "\n",
    "* **<code style=\"background:yellow;color:black\">Numpy creates a shallow copy WHEN RESHAPING.</code>**\n",
    "\n",
    "* So, what numpy has done internally, is that all the elements are shared between both the array \"a\" and \"b\", so that when we modify one of the elements of \"a\" array, since the memory address was common and since the elements were shared between the two arrays, the \"b\" array also got affected. \n",
    "* Here, numpy did not duplicate the data two times, what it did is actually created two pointers or references to that data, one reference was \"a\" and one reference was \"b\".\n",
    "* \"b\" and \"a\" were both looking at the data in different ways, but ultimately the data was exactly the same.\n",
    "\n",
    "### <code style=\"background:yellow;color:black\">shares_memory() function:</code>\n",
    "\n",
    "* **This is used to determine whether two arrays share the same memory block or addresses. This function returns a boolean value, indicating whether the two arrays share memory or not.**\n",
    "* **The np.shares_memory() function takes two NumPy arrays as arguments and checks if they have overlapping memory or if they are views of the same data. If they share memory, the function returns True; otherwise, it returns False.**\n",
    "* Through this function in next code cell below, we are checking and finding that \"a\" and \"b\" share memory and either one is the shallow copy of the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b6932e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87102d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(4)\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3232e12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.reshape(2, 2)\n",
    "\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed5bf4ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100,   1,   2,   3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0] = 100\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a523379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100,   1],\n",
       "       [  2,   3]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b158e5",
   "metadata": {},
   "source": [
    "**This means that either \"b\" is a shallow copy of \"a\" or \"a\" is a shallow copy of \"b\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8eed33c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shares_memory(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c7670b",
   "metadata": {},
   "source": [
    "### <code style=\"background:yellow;color:black\">Deep Copy of Data:</code> \n",
    "\n",
    "* **A deep copy of an array is a completely independent copy of the original array, which means it has its own memory address. In other words, both of these arrays have different memory addresses and are not sharing them.**\n",
    "* **Changes made to a deep copy do not affect the original array, and vice versa.**\n",
    "\n",
    "**Now, when is numpy creating deep copy or how it works?**\n",
    "\n",
    "* Below we created a 1D np array \"a\". \n",
    "* We also created another array \"c\" and make it \"a + 2\". \n",
    "* **<code style=\"background:yellow;color:black\">Numpy considers addition, subtraction, multiplication these kind of operations to be more permanent in nature, because all the individual elements are updated or changed i.e. data is changed.</code>** \n",
    "* So if we create \"c\" from \"a\", \"c\" has different data than \"a\". \n",
    "* Now if we check by \"shares_memory() function\", we will see that \"a\" and \"c\" do not share memory. \n",
    "* **We can further prove this by changing first element of \"c\" to 100, and \"c\" array gets updated as we can see below. <code style=\"background:yellow;color:black\">BUT ARRAY \"A\" IS NOT CHANGED AT ALL, ITS FIRST ELEMENT IS AS IT IS, IT HASNT CHANGED.</code>**\n",
    "* Why because \"c\" was stored in an entirely different memory location and \"a\" has been stored in an entirely different location and they do not share their memory addresses, and python can clear identify where \"a\" and \"c\" are located in memory locations.\n",
    "\n",
    "**\"C\" IS A DEEP COPY OF \"A\". Why do we say that c is a copy of a although c is altogether a different array in terms of data? - BECAUSE C COPIED THE DATA FROM A AND THEN MODIFIED THE DATA BY ADDING 2 TO IT. IN OTHER WORDS, C TOOK A DEEP COPY OF A AND THEN ADDED 2 TO IT.**\n",
    "\n",
    "**<code style=\"background:yellow;color:black\">Numpy does all this decisions on whether to share memory or not internally on its own, but numpy has given us shares_memory() function to check the memory sharing between two np arrays.</code>** \n",
    "\n",
    "* **Actually there are so many cases that in some memory is shared and in some memory isnt shared, and so remembering all those cases becomes difficult, so we have this function to check the same.**\n",
    "\n",
    "* **We will learn a sure shot way to understand where will numpy create a shallow copy and where will it create a deep copy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4988e1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fc0de62",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fc9f9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "812832a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 4, 5])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdb0d59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shares_memory(a, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55eda195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100,   3,   4,   5])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[0] = 100\n",
    "\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c975789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b05f929",
   "metadata": {},
   "source": [
    "**Now here in this case below, even though \"a\" and \"b\" both hold the same value or data, numpy does not share memory addresses of these arrays, and it created a deep copy because it figured that a multiplication operation requires a deep copy.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2603427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([0, 0, 0, 0])\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d5d4162",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a2c41e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0]), array([0, 0, 0, 0]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72ca0413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shares_memory(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc337ce8",
   "metadata": {},
   "source": [
    "* Here, in this case below, \"a\" and \"b\" have different data, they are not the same exact lists. \n",
    "* But in this case, numpy allows sharing memory addresses of these two arrays. \n",
    "* Lets look at it like the excel example previously. \n",
    "* We can see \"b\" as a filter that has been applied on \"a\" or that \"b\" is a subset of \"a\". \n",
    "* So all the data in \"b\" is still present inside of \"a\", which means if we modify the data in \"a\", data in \"b\" will be modified too because \"b\" is a subset of \"a\". \n",
    "* We change the 1st element in \"b\" to 1000 and we check \"a\" is also updated. \n",
    "* **REFER NOTES VERY WELL EXPLAINED WITH VISUALIZATION.**\n",
    "* So, here we see that 2 different np arrays dont necessarily share data but they can share memory addresses because one can be a subset of the other.\n",
    "<br><br>\n",
    "* Deep copy of one array wrt another array means both the arrays are stored at different memory locations in memory. \n",
    "* **<code style=\"background:yellow;color:black\">So, the cases are very varied apart. There can be cases where the data or values is different but a shallow copy is created and conversely there can be cases where the values can be same but the copy created is a deep copy.</code>** \n",
    "* **<code style=\"background:yellow;color:black\">NUMPY DECIDES INTERNALLY AUTOMATICALLY WHICH COPY TO CREATE OR WHICH FORMAT OR RULE TO FOLLOW, which is the reason numpy has given us this shares_memory() function.</code>** \n",
    "* We can try or explore further and see which cases create a deep copy and which creates a shallow one. See what copies different kind of operations like arithmetic, logical, masking, indexing, slicing etc create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e955c430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(10)\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb4a29db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 4, 6, 8])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a[::2]\n",
    "\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "810ae9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shares_memory(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36b298fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1000,    1,    2,    3,    4,    5,    6,    7,    8,    9])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0] = 1000\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "535f9d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0 % 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f34571",
   "metadata": {},
   "source": [
    "**This is another example to see if a shallow or deep copy is created, and we see a deep copy is created.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe037f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(6)\n",
    "\n",
    "b = a[a % 1 == 0]\n",
    "\n",
    "b[0] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3757e5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a972ab53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  1,  2,  3,  4,  5])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cfa75e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shares_memory(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831e1f27",
   "metadata": {},
   "source": [
    "So, up and untill this point of time in disussion, we can to understand the following:\n",
    "\n",
    "* **<code style=\"background:yellow;color:black\">Shallow Copy is created in these cases - Reshaping, Slicing....(and the list goes on which we can explore)</code>**\n",
    "* **<code style=\"background:yellow;color:black\">Deep Copy is created in these cases - Arithmetic Operations, Masking....(and the list goes on which we can explore)</code>**\n",
    "<br><br><br>\n",
    "* Now, we know numpy creates shallow and deep copies of arrays and it handles memory management on its own. \n",
    "* **<code style=\"background:yellow;color:black\">BUT WHAT IF WE WANT A SHALLOW OR DEEP COPY EXPLICITLY WITHOUT DOING ANY OPERATION ON THAT ARRAY, WITHOUT NUMPY DOING EVERYTHING ON ITS OWN, MEANS NUMPY DECIDING WHETHER IT WILL BE SHALLOW OR DEEP ON ITS OWN?</code>** \n",
    "\n",
    "### <code style=\"background:yellow;color:black\">view() method:</code> \n",
    "\n",
    "* **This <code style=\"background:yellow;color:black\">view() method</code> creates a shallow copy of the array. It is used to create a new array object that shares the same data with the original array.**\n",
    "* Changes to the data in the view will affect the original array, and vice versa.\n",
    "\n",
    "### <code style=\"background:yellow;color:black\">copy() method:</code> \n",
    "\n",
    "* **This <code style=\"background:yellow;color:black\">copy() method</code> always creates a deep copy of the array.**\n",
    "* It is explicitly designed to create an independent copy of the array, and modifications to the copied array do not affect the original.\n",
    "\n",
    "In the following examples we can see these methods in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0fef2658",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cefa530",
   "metadata": {},
   "source": [
    "**Creates a shallow copy of \"a\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d74ac778",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_shallow_copy = a.view() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd4a5899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shares_memory(a, a_shallow_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a4bef98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, a_shallow_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "79b9d480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([100,   1,   2,   3,   4,   5,   6,   7,   8,   9]),\n",
       " array([100,   1,   2,   3,   4,   5,   6,   7,   8,   9]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_shallow_copy[0] = 100\n",
    "\n",
    "a, a_shallow_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b219e7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a843a2",
   "metadata": {},
   "source": [
    "**Creates a deep copy of \"a\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7436aa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_deep_copy = a.copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1b5517d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shares_memory(a, a_deep_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d27126a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, a_deep_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "79166a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " array([100,   1,   2,   3,   4,   5,   6,   7,   8,   9]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_deep_copy[0] = 100\n",
    "\n",
    "a, a_deep_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508f28a2",
   "metadata": {},
   "source": [
    "### <code style=\"background:yellow;color:black\">Why we are learning this shallow and deep copies or memory management of numpy at a very higher level?</code>\n",
    "\n",
    "* We should be aware of it because numpy functions that way or uses it for memory optimization. \n",
    "* If we are not aware of this, then we might feel that our data is misbehaving. \n",
    "* We might not know why something else is changing while we are expecting something else. \n",
    "* So, its very important to know how numpy is handling the memory side of things. \n",
    "* **We wont be using this concepts directly for data science, but this is sort of going to get applied unintentionally and we dont have control over it, which is why we should have a great understanding of it.**\n",
    "\n",
    "We can dive deep between shallow and deep copies, we can refer to these official documetations of numpy:\n",
    "\n",
    "#### `.copy()` -- Returns copy of the array.\n",
    "\n",
    "Documentation (`.copy()`): https://numpy.org/doc/stable/reference/generated/numpy.ndarray.copy.html#numpy.ndarray.copy\n",
    "\n",
    "Documentation: (`np.copy()`): https://numpy.org/doc/stable/reference/generated/numpy.copy.html\n",
    "\n",
    "* When we are doing any operations on arrays, then numpy will decide automatically.\n",
    "* **<code style=\"background:yellow;color:black\">But when we want ourself to create a copy of array, then control is with us, we can decide whether we want a shallow copy or deep copy using .copy() or .view(), otherwise during operations as mentioned earlier numpy automatically decides because numpy handles memory allocations automatically.</code>**\n",
    "* Lets suppose we got a list that we need to sort. \n",
    "* But in our use case, we need to maintain or dont want to destroy the original list, so we will create a copy of it in another list and then sort that copied list. \n",
    "* Because lets suppose we need to present the original array and the sorted array both, so if we do an in-place sort on the original list, our unsorted original list is gone which we need to present somewhere. \n",
    "* One way of doing this is like the code below -- np.sort(a) doesnt sort the original \"a\" but creates a copy of \"a\" in a_sorted list and then sorts it.\n",
    "* Another way of doing it is to create a deep copy of \"a\" i.e. array \"b\". \n",
    "* We cant do a shallow copy of \"a\" because then if we would sort \"a\" then \"b\" would also change. So we can see in code below that \"b\" is sorted but \"a\" is not sorted.\n",
    "\n",
    "**<code style=\"background:yellow;color:black\">So, in any case where we have to maintain original data, where we cant loose the structure, order, authenticity of the original data but still we have to do multiple operations -- THERE WE WILL BE CREATING DEEP COPIES, i.e. copies of data which do not modify the original data.</code>** \n",
    "\n",
    "* We might do this frequently in data science.\n",
    "* When we will be exploring data, we will have to do a lot of operations on data and some of these operations will not be successful. \n",
    "* Whenever we will have unsuccessful operations, we will have to go back to the original data, but if we loose the original data, how will you do that? \n",
    "* **So if we do not create a deep copy of the original data, when we might have to reverse the operation we performed on data it will not be possible. So for these reasons we have to maintain deep copies.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fd752890",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([10, 15, 25, 5, 20, 0, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b45a206d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_sorted = np.sort(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bed17650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([10, 15, 25,  5, 20,  0, 30]), array([ 0,  5, 10, 15, 20, 25, 30]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, a_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b188034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ce76cc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "272e9ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  5, 10, 15, 20, 25, 30])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aa53682b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 15, 25,  5, 20,  0, 30])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f595b9cc",
   "metadata": {},
   "source": [
    "<hr style=\"border: 1px solid gray;\">\n",
    "\n",
    "# <code style=\"background:yellow;color:black\">Splitting Data:</code>\n",
    "\n",
    "* **<code style=\"background:yellow;color:black\">Splitting the data</code> means breaking the data into small pieces.** \n",
    "* In NumPy, the term \"splitting\" typically refers to the process of dividing an array into multiple smaller arrays along a specified axis. \n",
    "* NumPy provides several functions for splitting arrays, and the choice of function depends on the desired outcome.\n",
    "\n",
    "### <code style=\"background:yellow;color:black\">split() function:</code>\n",
    "\n",
    "* **The <code style=\"background:yellow;color:black\">split() function</code> allows us to split a NumPy array into multiple subarrays along a specified axis.** \n",
    "* It divides the original array into smaller, equally-sized parts (if possible) and returns a list of these subarrays. We specify the number of splits and the axis along which the split occurs.\n",
    "* **split() takes the following arguments:**\n",
    "    * **ary:** The array we want to split.\n",
    "    * **indices_or_sections:** It specifies how the array should be divided. It can be an integer, a list of indices, or a sequence of integers.\n",
    "    * **axis (optional):** The axis along which the array should be split. By default, it's 0, meaning the array is split along its first dimension.\n",
    "<br><br>\n",
    "* Splitting the array using split() is somewhat similar and different as well compared to splitting strings. \n",
    "* split() splits the array in similar fashion i.e. splitting something big into small small pieces but the way it works and the input it takes is different. \n",
    "\n",
    "**Because <code style=\"background:yellow;color:black\">np.split() can split arrays in 2 ways, either it can split in an \"n\" amount of sections or it can split about a given amount of indexes,</code> both ways are explained below.**\n",
    "\n",
    "**<u><code style=\"background:yellow;color:black\">Splitting in n sections:</code></u> Format: np.split(array, number_of_sections)**\n",
    "\n",
    "* If data is not divisible by number of sections, it will throw an error. \n",
    "* **SPLIT CAN ONLY AND ONLY WORK IF EVERY SINGLE SECTION WILL GET EQUIVALENT AMOUNT OF DATA. IF THE TOTAL NUMBER OF ELEMENTS IS NOT DIVISIBLE BY THE NUMBER OF SECTIONS WE INTEND TO MAKE, THEN THE SPLIT() FUNCTION WILL NOT WORK.** \n",
    "* Following examples shown below illustrate this.\n",
    "\n",
    "**<u><code style=\"background:yellow;color:black\">Splitting on the basis of exact indexes:</code></u> Format: np.split(array, [list_of_indexes])**\n",
    "\n",
    "* **Np will create a split right before that index.**\n",
    "* There is one more way when it comes to splitting np array. And that is by exact cutting points. \n",
    "* So lets supoose we got this entire array and we decided exactly where we want to split for example at index number 3 and at index number 5 and at index number 7. In the example below, we are splitting array \"b\" at indexes 3,5,9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "09b61a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(9)\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6104c435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 1, 2]), array([3, 4, 5]), array([6, 7, 8])]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.split(a, 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "93732bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.arange(14)\n",
    "\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b2c56d42",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "array split does not result in an equal division",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39msplit(b, \u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36msplit\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\lib\\shape_base.py:872\u001b[0m, in \u001b[0;36msplit\u001b[1;34m(ary, indices_or_sections, axis)\u001b[0m\n\u001b[0;32m    870\u001b[0m     N \u001b[38;5;241m=\u001b[39m ary\u001b[38;5;241m.\u001b[39mshape[axis]\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m N \u001b[38;5;241m%\u001b[39m sections:\n\u001b[1;32m--> 872\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    873\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124marray split does not result in an equal division\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array_split(ary, indices_or_sections, axis)\n",
      "\u001b[1;31mValueError\u001b[0m: array split does not result in an equal division"
     ]
    }
   ],
   "source": [
    "np.split(b, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1dbbcc3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cb622283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 1, 2]),\n",
       " array([3, 4]),\n",
       " array([5, 6, 7, 8]),\n",
       " array([ 9, 10, 11, 12, 13])]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.split(b, [3, 5, 9]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8b4fc8",
   "metadata": {},
   "source": [
    "### <code style=\"background:yellow;color:black\">np.array.split() function:</code>\n",
    "\n",
    "* We have to keep in mind that the total size of the array should be evenly divisible by the number of sections we specify. If not, we'll get a **ValueError** indicating that the split is not possible with equal-sized subarrays. \n",
    "* **In that case, we can also use <code style=\"background:yellow;color:black\">np.array_split() function</code> because it allows us to split an array into unequal parts.**\n",
    "\n",
    "Below is an example of the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "faab85fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 2, 3, 4]), array([5, 6, 7]), array([ 8,  9, 10])]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "# Split the array into three subarrays, which might have uneven sizes\n",
    "sub_arrays = np.array_split(arr, 3)\n",
    "\n",
    "sub_arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def7567b",
   "metadata": {},
   "source": [
    "* **If the data is huge in the form of a 2D array, lets suppose we are dividing the data into two equal halves.** \n",
    "* So first we will make sure that our data is divisible by 2. \n",
    "* **If our data is not divisible by 2, we will take out that last row and store it in a seperate array, and then we will split the data into 2, append the last row back whichever way we want to append.** \n",
    "* We dont need to know the exact size of the data because we only need to provide the number of sections, and if we want to verify if our data can be divided into those many sections, we can simply check the length of the data, which it will tell us how many rows of data we have. \n",
    "* **Here in below example, we have 9 element 1D array, and we want to split the data into 4 sections- namely \"w\", \"x\", \"y\", \"z\". So we will take out the last element and store it in \"z\" array, and then use the spilt() function to split the array in 3 equal parts \"w\", \"x\" and \"y\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d6b598c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4d06d4fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = a[-1]\n",
    "\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5eef89c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating remaining 3 sections by not splitting the entire array a, but splitting from 0 to -1\n",
    "\n",
    "w, x, y = np.split(a[0:-1], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1bcf3e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([3, 4, 5]), array([6, 7, 8]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88985e7b",
   "metadata": {},
   "source": [
    "### <code style=\"background:yellow;color:black\">np.hsplit() function:</code>\n",
    "\n",
    "**This <code style=\"background:yellow;color:black\">np.hsplit() function</code> splits an array horizontally (hsplit) along its columns or rows, respectively.**\n",
    "* It is convenient when working with two-dimensional arrays.\n",
    "* When it comes to 2D array, we can split data horizontally and we can split data vertically. To visualize more, REFER NOTES.\n",
    "* **This function splits the data on horizontal axis.**\n",
    "* It works in the exact same way as split() i.e. in \"n\" number of sections or at specific indexes.\n",
    "* Here in the code cell below, we are doing splitting by \"n\" number of sections.\n",
    "* In the next code cell below that, we are doing splitting by specific indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ee01d0f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5],\n",
       "       [ 6,  7,  8,  9, 10, 11],\n",
       "       [12, 13, 14, 15, 16, 17],\n",
       "       [18, 19, 20, 21, 22, 23],\n",
       "       [24, 25, 26, 27, 28, 29],\n",
       "       [30, 31, 32, 33, 34, 35]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(36).reshape(6, 6)\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "90b94909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0,  1],\n",
       "        [ 6,  7],\n",
       "        [12, 13],\n",
       "        [18, 19],\n",
       "        [24, 25],\n",
       "        [30, 31]]),\n",
       " array([[ 2,  3],\n",
       "        [ 8,  9],\n",
       "        [14, 15],\n",
       "        [20, 21],\n",
       "        [26, 27],\n",
       "        [32, 33]]),\n",
       " array([[ 4,  5],\n",
       "        [10, 11],\n",
       "        [16, 17],\n",
       "        [22, 23],\n",
       "        [28, 29],\n",
       "        [34, 35]])]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we are splitting by \"n\" number of sections.\n",
    "\n",
    "np.hsplit(a, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bff18b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0,  1],\n",
       "        [ 6,  7],\n",
       "        [12, 13],\n",
       "        [18, 19],\n",
       "        [24, 25],\n",
       "        [30, 31]]),\n",
       " array([[ 2,  3,  4],\n",
       "        [ 8,  9, 10],\n",
       "        [14, 15, 16],\n",
       "        [20, 21, 22],\n",
       "        [26, 27, 28],\n",
       "        [32, 33, 34]]),\n",
       " array([[ 5],\n",
       "        [11],\n",
       "        [17],\n",
       "        [23],\n",
       "        [29],\n",
       "        [35]])]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we are doing splitting by specific indexes.\n",
    "\n",
    "np.hsplit(a, [2,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c7b4a991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0,  1],\n",
       "        [ 6,  7],\n",
       "        [12, 13],\n",
       "        [18, 19],\n",
       "        [24, 25],\n",
       "        [30, 31]]),\n",
       " array([[ 2,  3,  4],\n",
       "        [ 8,  9, 10],\n",
       "        [14, 15, 16],\n",
       "        [20, 21, 22],\n",
       "        [26, 27, 28],\n",
       "        [32, 33, 34]]),\n",
       " array([[ 5],\n",
       "        [11],\n",
       "        [17],\n",
       "        [23],\n",
       "        [29],\n",
       "        [35]]),\n",
       " array([], shape=(6, 0), dtype=int32)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that there are no elements at 1000th index on horizontal axis, the index is out of range or out of bounds, \n",
    "# so it will still split but will return an empty array at the end, and not throw an error.\n",
    "# REFER NOTES FOR FOR CLARITY AND VIZUALIZATION.\n",
    "\n",
    "np.hsplit(a, [2,5,1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da68c83",
   "metadata": {},
   "source": [
    "### <code style=\"background:yellow;color:black\">np.vsplit() function:</code>\n",
    "\n",
    "* **This <code style=\"background:yellow;color:black\">np.vsplit() function</code> splits an array vertically (vsplit) along its columns or rows, respectively.**\n",
    "* It is convenient when working with two-dimensional arrays.\n",
    "* **This function splits the data on vertical axis.**\n",
    "* It works in the exact same way as split() i.e. in \"n\" number of sections or at specific indexes.\n",
    "* Here in the code cell below, we are doing splitting by \"n\" number of sections.\n",
    "* In the next code cell below that, we are doing splitting by specific indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "977489dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5],\n",
       "       [ 6,  7,  8,  9, 10, 11],\n",
       "       [12, 13, 14, 15, 16, 17],\n",
       "       [18, 19, 20, 21, 22, 23],\n",
       "       [24, 25, 26, 27, 28, 29],\n",
       "       [30, 31, 32, 33, 34, 35]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "eee0d092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0,  1,  2,  3,  4,  5],\n",
       "        [ 6,  7,  8,  9, 10, 11],\n",
       "        [12, 13, 14, 15, 16, 17]]),\n",
       " array([[18, 19, 20, 21, 22, 23],\n",
       "        [24, 25, 26, 27, 28, 29],\n",
       "        [30, 31, 32, 33, 34, 35]])]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splits the data on vertical axis\n",
    "\n",
    "np.vsplit(a, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "71aaff23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0, 1, 2, 3, 4, 5]]),\n",
       " array([[ 6,  7,  8,  9, 10, 11],\n",
       "        [12, 13, 14, 15, 16, 17],\n",
       "        [18, 19, 20, 21, 22, 23]]),\n",
       " array([[24, 25, 26, 27, 28, 29],\n",
       "        [30, 31, 32, 33, 34, 35]])]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we are doing splitting by specific indexes.\n",
    "\n",
    "np.vsplit(a, [1, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c525f9",
   "metadata": {},
   "source": [
    "<hr style=\"border: 1px solid gray;\">\n",
    "\n",
    "# <code style=\"background:yellow;color:black\">Stacking Data:</code>\n",
    "\n",
    "* **In NumPy, <code style=\"background:yellow;color:black\">stacking refers to the process of combining or concatenating multiple arrays into a single array.</code>** NumPy provides several functions to stack arrays in different ways, such as horizontally, vertically, or depth-wise.\n",
    "* This is the opposite of splitting data, means joining data together, merging or stacking. So, we can stack data vertically and we can stack data horizontally. REFER NOTES HERE.\n",
    "\n",
    "### <code style=\"background:yellow;color:black\">vstack() function:</code>\n",
    "\n",
    "* **In NumPy, the <code style=\"background:yellow;color:black\">np.vstack() function</code> is used to vertically stack or concatenate two or more arrays along their rows. It takes a sequence of arrays as its argument and returns a new array with the input arrays stacked on top of each other.** \n",
    "\n",
    "* **The primary argument of np.vstack() is:**\n",
    "    * **tup:** This is a tuple or sequence of arrays that you want to stack vertically.\n",
    "    * Note that vstack() function can have list as an argument or tuple as an argument too.\n",
    "<br><br>\n",
    "* In the below example, same \"data\" is stacked on top of one another in total 3 times.\n",
    "* So, np.vstack((data, data, data)) would work too, note that data is provided as a tuple as argument to vstack().\n",
    "* **<code style=\"background:yellow;color:black\">Also note that the shapes of all arrays should be same in order for vstack to work.</code>** There is a very legitimate reason for this. \n",
    "* Lets suppose we have data of stocks for 2015 to 2022. Now if we are adding data below it, the dimensions of the data have to mactch right. Otherwise the data would not make sense, the header would be something else the value would be something else or there will be a header and the value would be missing. \n",
    "* **So, <code style=\"background:yellow;color:black\">when there is data that needs to be stacked or combined VERTICALLY,</code> the data that is getting added should have the exact same number of columns. The number of rows can be different.**\n",
    "* Note that in the example below \"a\" is a 1D array with 4 elements and \"b\" is a 2D array with shape of 4,4 and has 16 elements. * Here, \"a\" and \"b\" has different number of rows but same number of columns. So, vstack() works.\n",
    "* **<code style=\"background:yellow;color:black\">When there is data that needs to be stacked or combined HORIZONTALLY,</code> the data that is getting added should have the exact same number of rows. The number of columns can be different.**\n",
    "* These all concepts are explained below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "314ba992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.arange(5)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0f6579d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack([data, data, data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a72e838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE THAT SHAPES OF ALL ARRAYS ARE SAME SO VSTACK WORKS.\n",
    "\n",
    "a = np.arange(1, 5)\n",
    "b = np.arange(2, 6)\n",
    "c = np.arange(3, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7848c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [2, 3, 4, 5],\n",
       "       [3, 4, 5, 6]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is different data stacked on top of one another in total 3 times.\n",
    "\n",
    "np.vstack([a, b, c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b39f6f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE THAT SHAPES OF ALL ARRAYS ARE DIFFERENT SO VSTACK DOES NOT WORK.\n",
    "\n",
    "a = np.arange(1, 5)\n",
    "b = np.arange(2, 4)\n",
    "c = np.arange(3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0fbb3a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 4 and the array at index 1 has size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39mvstack([a, b, c])\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\core\\shape_base.py:296\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(tup, dtype, casting)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    295\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m [arrs]\n\u001b[1;32m--> 296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _nx\u001b[38;5;241m.\u001b[39mconcatenate(arrs, \u001b[38;5;241m0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype, casting\u001b[38;5;241m=\u001b[39mcasting)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 4 and the array at index 1 has size 2"
     ]
    }
   ],
   "source": [
    "np.vstack([a, b, c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46990550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(1, 5)\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d29d3f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [12, 13, 14, 15]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.arange(16).reshape(4, 4)\n",
    "\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "994ea629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [12, 13, 14, 15],\n",
       "       [ 1,  2,  3,  4]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack([b, a])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd6899c",
   "metadata": {},
   "source": [
    "### <code style=\"background:yellow;color:black\">hstack() function:</code>\n",
    "\n",
    "* **In NumPy, the <code style=\"background:yellow;color:black\">np.hstack() function</code> is used to horizontally stack or concatenate two or more arrays along their columns. It takes a sequence of arrays as its argument and returns a new array with the input arrays stacked adjacent to each other.** \n",
    "* **The primary argument of np.vstack() is:**\n",
    "    * **tup:** This is a tuple or sequence of arrays that you want to stack vertically.\n",
    "    * Note that vstack() function can have list as an argument or tuple as an argument too.\n",
    "* Here in the example below, \"a\" and \"b\" have same number of rows but different nnumber of columns. So hstack() works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84540156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(5).reshape(5, 1)\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd9f3e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2],\n",
       "       [ 3,  4,  5],\n",
       "       [ 6,  7,  8],\n",
       "       [ 9, 10, 11],\n",
       "       [12, 13, 14]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.arange(15).reshape(5, 3)\n",
    "\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7b345caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  1,  2],\n",
       "       [ 1,  3,  4,  5],\n",
       "       [ 2,  6,  7,  8],\n",
       "       [ 3,  9, 10, 11],\n",
       "       [ 4, 12, 13, 14]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here a and b have same number of rows but different nnumber of columns. So hstack() works.\n",
    "\n",
    "np.hstack([a, b])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de83867",
   "metadata": {},
   "source": [
    "<hr style=\"border: 1px solid gray;\">\n",
    "\n",
    "# <code style=\"background:yellow;color:black\">Concatenate Data:</code>\n",
    "\n",
    "* **<code style=\"background:yellow;color:black\">Concatenate</code>is one more way of doing stacking only, but it is like a combination function for both hstack and vstack, means it is a combined version of hstack and vstack.**\n",
    "\n",
    "### <code style=\"background:yellow;color:black\">concatenate() function:</code>\n",
    "\n",
    "* **In NumPy, the <code style=\"background:yellow;color:black\">np.concatenate() function</code> is a more general-purpose function for concatenating two or more arrays along an existing axis. It allows us to concatenate arrays along any specified axis, not just the second axis (as with np.hstack() or np.vstack()).** \n",
    "* **The general syntax is: np.concatenate((array1, array2, ...), axis = 0, out = None)**\n",
    "    * array1, array2, ...: Sequence of arrays that we want to concatenate.\n",
    "    * axis: Axis along which the arrays will be joined. Default is 0 (concatenate along the first axis).\n",
    "    * out: Optional parameter providing a location where the result is stored.\n",
    "<br><br>\n",
    "\n",
    "* **For concatenate to work, there is a very very important constraint that both the arrays should have the same number of dimensions.** \n",
    "* Here in below example, array \"a\" is 1D and array \"b\" is 2D. So, concatenate will not work. So, there is a smart workaround. \n",
    "* Simply convert 1D to 2D which is done below after the error. And that is by applying one more set of [] in a to make it a list inside a list i.e. 2D. Axis 0 means we are concatenating vertically. \n",
    "\n",
    "**<code style=\"background:yellow;color:black\">When it comes to concatenate there are following rules:</code>**\n",
    "1. **Number of dimensions must be same**\n",
    "2. **Axis -** \n",
    "    * vstack -> axis = 0\n",
    "    * hstack -> axis = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6ca04fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "b = np.array([[1, 2, 3], [4, 5, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9c3a081b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "95173b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6a8e86af",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[91], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39mconcatenate([a, b], axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)"
     ]
    }
   ],
   "source": [
    "np.concatenate([a, b], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77997f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2, 3]])\n",
    "b = np.array([[1, 2, 3], [4, 5, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d32a7196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a and b have same number of columns, so they can be concatenated vertically. Note that axis = 0.\n",
    "\n",
    "np.concatenate([a, b], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0cd9159b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(4).reshape(2, 2)\n",
    "b = np.arange(8).reshape(2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0cb0b484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42a040a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3],\n",
       "       [4, 5, 6, 7]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f743d3f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3, 0, 1],\n",
       "       [4, 5, 6, 7, 2, 3]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a and b have same number of rows, so they can be concatenated horizontally. Note that axis = 1.\n",
    "\n",
    "np.concatenate([b, a], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5450e20f",
   "metadata": {},
   "source": [
    "**<code style=\"background:yellow;color:black\">IMPORTANT:</code>**\n",
    "\n",
    "* We dont have joins like sql in numpy or python. Why would we do sql joins in numpy? We have joins in sql so we dont need them in numpy. Means we do joins in sql and then we dont require joins operation in python. \n",
    "* **There is a concept called DATA PIPELINE. Everyone of these tools, like sql, tableau, excel, python, numpy plays a seperate role in this data pipeline. As a data analyst, its not that we will either use sql or we will use tableau or we will use python. WE WILL ACTUALLY USE ALL OF THESE TOOLS.** \n",
    "* **SQL WILL BE FOR FETCHING DATA, PYTHON WILL BE FOR WORKING ON DATA.** \n",
    "* Within python also there will be two options one is numpy and one is pandas. \n",
    "* Numpy is like the brain behind pandas. And, pandas has been built on top of numpy to work beautifully with data. \n",
    "* **So everything and anything that we feel is required directly for data, we will find it in pandas and not numpy. SO WE USE BOTH NUMPY AND PANDAS TOGETHER.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "100fa998",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2], [3, 4]])\n",
    "b = np.array([[5, 6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b91b1f",
   "metadata": {},
   "source": [
    "* In above example, \"a\" and \"b\" both are nested arrays or 2D arrays. \n",
    "* **Now in below code, we are providing axis = None.** \n",
    "* Numpy has a special feature via which it will just flatten the entire array. \n",
    "* **<code style=\"background:yellow;color:black\">What soes flattening mean? It means REMOVING NESTING. Removing dimensions, converting everything to one single dimension.</code>** \n",
    "* Concatenate has this special feature.\n",
    "\n",
    "### <code style=\"background:yellow;color:black\">flatten() method:</code>\n",
    "\n",
    "**In NumPy, the <code style=\"background:yellow;color:black\">flatten() method</code> is used to return a copy of the array collapsed into a one-dimensional array. The original array remains unchanged. The flatten() method always returns a flat copy of the original array, even if the original array is already one-dimensional.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91e0151e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([a, b], axis = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c34cf423",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'flatten'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39mflatten([[[[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]], [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m6\u001b[39m]]])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\__init__.py:320\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tester\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Tester\n\u001b[1;32m--> 320\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'flatten'"
     ]
    }
   ],
   "source": [
    "np.flatten([[[[1, 2, 3]], [2, 3, 4, 5, 5, 6, 6]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d928d85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3],\n",
       "       [ 5,  6,  7],\n",
       "       [ 8,  9, 10]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1, 2, 3], [5, 6, 7], [8, 9, 10]])\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "348b825e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.flatten()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
